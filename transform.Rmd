# Transformación de Datos {#transforma}

## Introducción

La visualización es una herramienta importante para el análisis exploratorio, sin embargo es raro que obtengas los datos exactamente en la forma correcta que necesitas. A menudo necesitarás crear variables o estadísticos nuevos, o tal vez solo quieras cambiar el nombre de las variables o reordenar las observaciones para facilitar el trabajo con los datos. En este capítulo aprenderás cómo hacer todo eso (¡y más!), incluyendo cómo transformar tus datos utilizando el paquete dplyr. Utilizaremos un nuevo conjunto de datos sobre salida de vuelos de la ciudad de Nueva York en el año 2013.

### Prerequisitos

En este capítulo nos enfocaremos en cómo usar el paquete dplyr, otro miembro central del tidyverse. Ilustraremos las ideas clave con los datos del paquete vuelos y usaremos ggplot2 para ayudarnos a comprender los datos. 

```{r setup, message = FALSE}
devtools::install_github("cienciadedatos/datos")
data(package = "datos")
library(nycvuelos13)
library(tidyverse)
```

Toma nota acerca del mensaje de conflictos que se imprime cuando carga el paquete tidyverse. Te dice que dplyr sobrescribe algunas funciones en la base de R. Si deseas usar la versión base de estas funciones después de cargar dplyr, necesitarás usar sus nombres completos: `stats::filter()` y `stats::lag()`.

### vuelos

Para explorar los verbos básicos de manipulación de datos de dplyr, usaremos `datos::vuelos`. Este conjunto de datos contiene todos los vuelos `formato r (nrow (datos::vuelos), big.mark =", ")` que partieron de la ciudad de Nueva York durante el 2013. Los datos provienen de las estadísticas de la [Oficina de Transportes de los Estados Unidos](https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&Link=0), y están documentados en `? datos`.

```{r}
vuelos
```

Es posible que observes que este conjunto de datos se imprime de una forma un poco diferente a otros que podrías haber utilizado en el pasado: solo muestra las primeras filas y todas las columnas que caben en tu pantalla. Para ver todo el conjunto de datos, puedes ejecutar `View(vuelos)` que abrirá el conjunto de datos en el visor de RStudio. En este caso se imprime de manera diferente porque es un __tibble__. Los Tibbles son marcos de datos, pero ligeramente ajustados para que funcionen mejor en el tidyverse. Por ahora, no necesitas preocuparte por las diferencias; volveremos a tibbles con más detalle en [doma] (# doma-intro).

También podrás haber notado la fila de tres (o cuatro) abreviaturas de letras debajo de los nombres de las columnas. Estos describen el tipo de cada variable:

* `int` significa enteros.

* `dbl` representa dobles, o números reales.

* `chr` significa vectores de caracteres o cadenas.

* `dttm` significa fechas y horas (una fecha + una hora).

Hay otros tres tipos comunes de variables que no se usan en este conjunto de datos, pero que encontrará más adelante en el libro:

* `lgl` significa vectores lógicos que solo contienen ` TRUE` (verdadero) o `FALSE` (falso).

* `fctr` significa factores, que R usa para representar variables categóricas con valores posibles fijos.

* `date` significa fechas.

### Lo básico de dplyr 

En este capítulo, aprenderás las cinco funciones clave de dplyr que te permiten resolver la gran mayoría de tus desafíos de manipulación de datos:

* Filtra o elije las observaciones por sus valores (`filter()` — del inglés filtrar).
* Reordena las filas (`arrange()` — del inglés arreglar).
* Selecciona las variables por sus nombres (`select()` — del inglés seleccionar).
* Crea nuevas variables con transformaciones de variables existentes (`mutate()` — del inglés mutar o transformar).
* Contraer muchos valores hasta un solo resumen (`summarize()` — del inglés resumir).

Todo esto se puede usar junto con `group_by()` (— agrupar por en inglés), que cambia el alcance de cada función para que funcione ya no en todo el conjunto de datos sino que funcione grupo por grupo. Estas seis funciones proporcionan los verbos para un lenguaje de manipulación de datos.

Todos los verbos funcionan de manera similar:

1. El primer argumento es un marco de datos.

2. Los argumentos posteriores describen qué hacer con el marco de datos usando los nombres de variables (sin comillas).

3. El resultado es un nuevo marco de datos.

En conjunto, estas propiedades hacen que sea fácil encadenar varios pasos simples para lograr un resultado complejo. Vamos a sumergirnos y ver cómo funcionan estos verbos.

## Filtrar filas con `filter()`

`filter()` te permite filtrar un subconjunto de observaciones basadas en sus valores. El primer argumento es el nombre del marco de datos. El segundo y siguientes argumentos son las expresiones que filtran el marco de datos. Por ejemplo, podemos seleccionar todos los vuelos del 1 de enero con:

```{r}
filter(vuelos, mes == 1, dia == 1)
```

Cuando ejecutas esa línea de código, dplyr ejecuta la operación de filtrado y devuelve un nuevo marco de datos. Las funciones dplyr nunca modifican sus entradas, por lo que si deseas guardar el resultado, necesitarás usar el operador de asignación, `<-`:

```{r}
ene1 <- filter(vuelos, mes == 1, dia == 1)
```

R imprime los resultados o los guarda en una variable. Si deseas hacer ambas cosas, puedes escribir toda la línea entre paréntesis:

```{r}
(dic25 <- filter(vuelos, mes == 12, dia == 25))
```

### Comparaciones

Para usar el filtrado de manera efectiva, debes saber cómo seleccionar las observaciones que deseas utilizando los operadores de comparación. R proporciona la suite estándar: `>`, `> =`, `<`, `<=`, `! =` (No igual) y `==` (igual).

Cuando comienzas con R, el error más fácil de cometer es usar `=` en lugar de `==` cuando se prueba la igualdad. Cuando esto sucede, obtendrás un error informativo:

```{r, error = TRUE}
filter(vuelos, mes = 1)
```

Hay otro problema común que puedes encontrar al usar `==`: números de coma flotante. ¡Estos resultados pueden sorprenderte!

```{r}
sqrt(2) ^ 2 == 2
1 / 49 * 49 == 1
```

Las computadoras usan aritmética de precisión finita (obviamente no pueden almacenar una cantidad infinita de dígitos) Así que recuerda que cada número que ves es una aproximación. En lugar de confiar en `==`, usa `near()` (cercano en inglés):

```{r}
near(sqrt(2) ^ 2,  2)
near(1 / 49 * 49, 1)
```

### Operadores lógicos

Múltiples argumentos para `filter()` se combinan con "y": cada expresión debe ser verdadera para que una fila se incluya en la salida. Para otros tipos de combinaciones, necesitarás usar operadores Booleanos: `&` es "y", `|` es "o", y `!` Es "no". La figura @ref(fig:bool-ops) muestra el conjunto completo de operaciones Booleanas.

```{r bool-ops, echo = FALSE, fig.cap = "Set Completo de Operaciones Booleanas. `x` es el círculo de la izquierda, `y` es el círculo de la derecha, y la región sombreada muestra qué partes selecciona cada operador."}
knitr::include_graphics("diagrams/transform-logical.png")
```

El siguiente código encuentra todos los vuelos que partieron en noviembre o diciembre:

```{r, eval = FALSE}
filter(vuelos, mes == 11 | mes == 12)
```

El orden de las operaciones no funciona como en español. No puedes escribir `filter (vuelos, mes == 11 | 12)`, que literalmente puede traducirse como "encuentra todos los vuelos que partieron en noviembre o diciembre". En cambio, encontrará todos los meses que son iguales a `11 | 12`, una expresión que evalúa a 'VERDADERO'. En un contexto numérico (como aquí), 'VERDADERO' se convierte en un uno, por lo que encuentra todos los vuelos en enero, no en noviembre o diciembre. Esto es bastante confuso.

Una manera rápida y útil para resolver este problema es `x %in% y` (x en y en inglés). Esto seleccionará cada fila donde `x` es uno de los valores en` y`. Podríamos usarlo para reescribir el código de arriba:

```{r, eval = FALSE}
nov_dic <- filter(vuelos, mes %in% c(11, 12))
```

A veces puedes simplificar subconjuntos complicados al recordar la ley de De Morgan: `!(x & y)` es lo mismo que `!x | !y`, y `!(x | y)` es lo mismo que `!x & !y`. Por ejemplo, si deseas encontrar vuelos que no se retrasaron (en llegada o partida) en más de dos horas, puedes usar cualquiera de los dos filtros siguientes:

```{r, eval = FALSE}
filter(vuelos, !(lleg_tardia > 120 | sal_tardia > 120))
filter(vuelos  , lleg_tardia <= 120, sal_tardia <= 120)
```

Además de `&` y `|`, R también tiene `&&` y `||`. ¡No los uses aquí! Aprenderás cuándo debe usarlos en [ejecución condicional].

Siempre que empieces a usar expresiones complejas de varias partes en `filter()`, considera convertirlas en variables explícitas. Eso hace que sea mucho más fácil verificar tu trabajo. Aprenderás cómo crear nuevas variables en breve.

### Valores faltantes

Una característica importante de R que puede hacer que la comparación sea difícil son los valores faltantes, o `NA`s ("no disponibles en inglés"). `NA` representa un valor desconocido por lo que los valores perdidos son "contagiosos": casi cualquier operación que involucre un valor desconocido también será desconocida.

```{r}
NA > 5
10 == NA
NA + 10
NA / 2
```

El resultado más confuso es este:

```{r}
NA == NA
```

Es más fácil entender por qué esto es cierto con un poco más de contexto:

```{r}
# Sea x la edad de María. No sabemos qué edad tiene.
x <- NA

# Sea y la edad de Juan. No sabemos qué edad tiene.
y <- NA

# ¿Tienen Juan y María la misma edad?
x == y
# ¡No sabemos!
```

Si deseas determinar si falta un valor, usa `is.na()`:

```{r}
is.na(x)
```

`filter()` solo incluye filas donde la condición es `TRUE`; excluye ambos valores `FALSE` y `NA`. Si deseas conservar valores perdidos, solicítalos explícitamente:

```{r}
df <- tibble(x = c(1, NA, 3))
filter(df, x > 1)
filter(df, is.na(x) | x > 1)
```

### Ejercicios

1.  Encuentra todos los vuelos que:

   i.   Tuvieron un retraso de llegada de dos o más horas
  
   ii.  Volaron a Houston (`IAH` o` HOU`)
   
   iii. Fueron operados por United, American o Delta
   
   iv.  Partieron en verano (julio, agosto y septiembre)
   
   v.   Llegaron más de dos horas tarde, pero no salieron tarde
   
   vi.  Se retrasaron por lo menos una hora, pero repusieron más de 30 minutos en vuelo
   
   vii. Partieron entre la medianoche y las 6 a.m. (inclusive)

2.  Otro filtrado útil de dplyr es `between()`. ¿Qué hace? ¿Puedes usarlo para simplificar el código necesario para responder a los desafíos anteriores?

3. ¿Cuántos vuelos tienen datos faltantes de `dep_time`? ¿Qué otras variables tienen valores faltantes? ¿Qué representan estas filas?

4. ¿Por qué `NA ^ 0` no es faltante? ¿Por qué `NA | TRUE` no es faltante? ¿Por qué `FALSE & NA` no es faltante? ¿Puedes descubrir la regla general? (`NA * 0` es un contraejemplo complicado!)

## Reordena las filas con `arrange()`

`arrange()` funciona de manera similar a `filter()` excepto que en lugar de seleccionar filas, cambia su orden. La función toma un marco de datos y un conjunto de nombres de columna (o expresiones más complicadas) para ordenar acorde. Si proporcionas más de un nombre de columna, cada columna adicional se utilizará para romper empates en los valores de las columnas anteriores:

```{r}
arrange(vuelos, anio, mes, dia)
```

Usa `desc()` para reordenar por una columna en orden descendente:

`` `{r}
arrange(vuelos, desc(sal_tardia))
`` `

Los valores faltantes siempre se ordenan al final:

```{r}
df <- tibble(x = c (5, 2, NA))
arrange(df, x)
arrange(df, desc(x))
```

### Ejercicios

1. ¿Cómo podrías usar `arrange()` para ordenar todos los valores perdidos al comienzo? (Sugerencia: usa `is.na()`).
    
2. Ordena `vuelos` para encontrar los vuelos más retrasados. Encuentra los vuelos que salieron más temprano.

3. Ordena `vuelos` para encontrar los vuelos más rápidos.

4. ¿Cuáles vuelos viajaron más tiempo? ¿Cuál viajó menos tiempo?

## Selecciona columnas con `select()` {#selecciona}

No es raro obtener conjuntos de datos con cientos o incluso miles de variables. En este caso, el primer desafío a menudo se reduce a las variables que realmente te interesan. `select()` te permite seleccionar rápidamente un subconjunto útil utilizando operaciones basadas en los nombres de las variables.

`select()` no es muy útil con los datos de los vuelos porque solo tenemos 19 variables, pero aún podemos describir la idea general:

```{r}
# Seleccionar columnas por nombre
select(vuelos, anio, mes, día)
# Seleccionar todas las columnas entre año y día (inclusive)
select(vuelos, anio: día)
# Seleccionar todas las columnas excepto aquellas entre año en día (inclusive)
select(vuelos, - (anio: día))
```

Hay una serie de funciones auxiliares que puede usar dentro de `select()`:

* `starts_with("abc")`: coincide con nombres que comienzan con "abc".

* `ends_with("xyz")`: coincide con los nombres que terminan con "xyz".

* `contains("ijk")`: coincide con los nombres que contienen "ijk".

* `matches("(.)\\1")`: selecciona variables que coinciden con una expresión regular. Éste coincide con cualquier variable que contenga caracteres repetidos. Aprenderás más sobre expresiones regulares en [strings].

* `num_range("x", 1:3)`: coincide con `x1`,` x2` y `x3`.

Ver `?select` para más detalles.

`select()` se puede usar para cambiar el nombre de las variables, pero rara vez es útil porque descarta todas las variables que no se mencionan explícitamente. En su lugar, utiliza `rename()`, que es una variante de `select()` que mantiene todas las variables que no se mencionan explícitamente:

`` `{r}
rename(vuelos, cola_num = colanum)
`` `

Otra opción es usar `select()` junto con el asistente `everything()` (todo en inglés). Esto es útil si tienes un grupo de variables que te gustaría mover al comienzo del marco de datos.

```{r}
select(vuelos, time_hour, air_time, everything())
```

### Ejercicios

1. Haz una lluvia de ideas de tantas maneras como sea posible para seleccionar `dep_time`,` dep_delay`,`arr_time`, y` arr_delay` de `vuelos`.

2. ¿Qué sucede si incluyes el nombre de una variable varias veces en una llamada `select()`?

3. ¿Qué hace la función `one_of()`? Por qué podría ser útil en conjunto con este vector?

```{r}
vars <- c ("anio", "mes", "día", "dep_delay", "arr_delay")
```

4. ¿Te sorprende el resultado de ejecutar el siguiente código? ¿Cómo tratan el caso por defecto los ayudantes seleccionados? ¿Cómo puedes cambiar ese valor predeterminado?

```{r, eval = FALSE}
select(vuelos, contains("HORA"))
```

## Crea nuevas variables con `mutate()`

Además de seleccionar conjuntos de columnas existentes, a menudo es útil crear nuevas columnas como funciones de columnas existentes. Ese es el trabajo de `mutate()` (mutar en inglés).

`mutate()` siempre agrega nuevas columnas al final de st conjunto de datos, así que comenzaremos creando un conjunto de datos más pequeño para que podamos ver las nuevas variables. Recuerda que cuando usas RStudio, la manera más fácil de ver todas las columnas es `View()`.

```{r}
vuelos_sml <- select(vuelos,
  anio:dia,
  ends_with("retraso"),
  distancia,
  air_time
)
mutate(vuelos_sml,
  gain = dep_delay - arr_delay,
  velocidad = distancia / tiempo_viento * 60
)
```

Ten en cuenta que puedes consultar las columnas que acabas de crear:

```{r}
mutate(vuelos_sml,
  gain = dep_delay - arr_delay,
  horas = air_time / 60,
  gain_per_hour = ganancia / horas
)
```

Si solo quiere conservar las nuevas variables, use `transmute ()`:

```{r}
transmutate(vuelos_sml,
  gain = dep_delay - arr_delay,
  horas = air_time / 60,
  gain_per_hour = ganancia / horas
)
```

### Funciones de creación útiles {# mutate-funs}

Hay muchas funciones para crear nuevas variables que se puede usar con `mutate()`. La propiedad clave es que la función debe ser vectorizada: debe tomar un vector de valores como input, y devolver un vector con el mismo número de valores como output. No hay forma de enumerar todas las posibles funciones que podrías usar, pero aquí hay una selección de funciones que son útiles frecuentemente:

* Operadores aritméticos: `+`, `-`,`*`,`/`,`^`. Todos están vectorizados, usando las llamadas "reglas de reciclaje". Si un parámetro es más corto que el otro, se extenderá automáticamente para tener la misma longitud. Esto es muy útil cuando uno de los argumentos es un solo número: `air_time / 60`, `horas * 60 + minuto`, etc. Los operadores aritméticos también son útiles junto con el funciones de agregar de las que aprenderás más tarde. Por ejemplo, `x / sum (x)` calcula la proporción de un total, y `y - media (y)` calcula la diferencia de la media.

* Aritmética modular: `%/%` (división entera) y `%%` (resto), donde `x == y * (x%/% y) + (x %% y)`. La aritmética modular es una herramienta útil porque te permite dividir enteros en partes. Por ejemplo, en el conjunto de datos de vuelos, puedes calcular `hour` y` minute` de `dep_time` con:

```{r}
transmute(vuelos,
  dep_time,
  hora = dep_time% /% 100,
  minuto = dep_time %% 100
)
```

* Logaritmos: `log()`, `log2()`, `log10()`. Los logaritmos son increíblemente útiles como transformación para hacer frente a los datos con múltiples órdenes de magnitud. También convierten las relaciones multiplicativas en aditivos, una característica muy útil para el modelado. En igualdad de condiciones, recomendamos usar `log2()` porque es más fácil de interpretar: una diferencia de 1 en la escala de registro corresponde a la duplicación de la escala original y una diferencia de -1 corresponde a la mitad.

* Rezagos: `lead()` y `lag()` te permiten referirte a un valor adelante o un valor atrás (con rezago). Esto te permite calcular las diferencias móviles (por ejemplo, `x - lag(x)`) o buscar cuáles y dónde cambian los valores (`x! = lag (x)`). Estos comandos son más útiles cuando se utilizan junto con `group_by()`, que lo aprenderás en breve.

```{r}
(x <- 1:10)
lag(x)
lead(x)
```

* Agregados acumulativos y acumulados: R proporciona funciones para ejecutar sumas, productos, mínimos y máximos: `cumsum()`, `cumprod()`, `cummin()`, `cummax()`; y dplyr proporciona `cummean()` para la media acumulada. Si necesitas calcular agregados móviles (es decir, una suma calculada en una ventana móvil), prueba el paquete RcppRoll.

```{r}
x
cumsum(x)
cummean(x)
```

* Comparaciones lógicas: antes aprendimos: `<`, `<=`, `>`, `> =`, `! =`. Si estás haciendo una secuencia compleja de operaciones lógicas, es a menudo es una buena idea almacenar los valores provisionales en nuevas variables para que puedas comprobar que cada paso funciona como se espera.

* Clasificación: hay una serie de funciones de clasificación, pero deberías comenzar con `min_rank()`. Esta función realiza el tipo más común de clasificación (por ejemplo, primero, segundo, tercero, etc). El valor predeterminado otorga la menor posición a los valores más pequeños; usa `desc(x)` para dar la menor posición a los valores más grandes.

```{r}
y <- c (1, 2, 2, NA, 3, 4)
min_rank(y)
min_rank(desc(y))
```

Si `min_rank()` no hace lo que necesitas, consulta las variantes `row_number()`, `dense_rank()`, `percent_rank()`, `cume_dist()`,
`ntile()`. Ve sus páginas de ayuda para más detalles.

```{r}
row_number(y)
dense_rank(y)
percent_rank(y)
cume_dist(y)
```

### Ejercicios

```{r, eval = FALSE, echo = FALSE}
vuelos <- vuelos %>% mutate(
  dep_time = hour * 60 + minute,
  arr_time = (arr_time %/% 100) * 60 + (arr_time %% 100),
  airtime2 = arr_time - dep_time,
  dep_sched = dep_time + dep_delay
)

ggplot(vuelos, aes(dep_sched)) + geom_histogram(binwidth = 60)
ggplot(vuelos, aes(dep_sched %% 60)) + geom_histogram(binwidth = 1)
ggplot(vuelos, aes(air_time - airtime2)) + geom_histogram()
```

1. Las variables `dep_time` y` sched_dep_time` tienen un formato conveniente para leer, pero es difícil realizar cualquier cálculo con ellas porque no son realmente números continuos. Conviértelos en una representación más conveniente de la cantidad de minutos desde la medianoche.

2. Compara `air_time` con` arr_time - dep_time`. ¿Qué esperas ver? ¿Qué ves? ¿Qué necesitas hacer para arreglarlo?

3. Compara `dep_time`,` sched_dep_time`, y `dep_delay`. ¿Cómo esperarías que esos tres números estén relacionados?

4. Encuentra los 10 vuelos más retrasados utilizando una función de clasificación. ¿Cómo quieres para manejar los empates? Lee atentamente la documentación de `min_rank()`.

5. ¿Qué devuelve `1: 3 + 1: 10`? ¿Por qué?

6. ¿Qué funciones trigonométricas proporciona R?

## Resúmenes agrupados con `summarize()`

El último verbo clave es `summarize()` (de resumir en inglés). Se encarga de colapsar un marco de datos en una sola fila:

`` `{r}
summarize(vuelos, demora = mean(dep_delay, na.rm = TRUE))
`` `

(Volveremos a lo que significa `na.rm = TRUE` en muy poco tiempo).

`summarize()` no es muy útil a menos que lo emparejemos con `group_by()`. Esto cambia la unidad de análisis del conjunto de datos completo a grupos individuales. Luego, cuando uses los verbos dplyr en un marco de datos agrupado, aplicarás automáticamente "por grupo". Por ejemplo, si aplicamos exactamente el mismo código a un marco de datos agrupado por fecha, obtenemos el retraso promedio por fecha:

```{r}
by_day <- group_by (vuelos, anio, mes, dia)
summarize(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

Juntos `group_by ()` y `summarize ()` proporcionan una de las herramientas que usarás más comúnmente cuando trabajes con dplyr: resúmenes agrupados. Pero antes de ir más allá con esto, tenemos que introducir una idea nueva y poderosa: la tubería o dataducto.

### Combinación de múltiples operaciones con la tubería

Imagina que queremos explorar la relación entre la distancia y la demora promedio para cada ubicación. Usando lo que sabes acerca de dplyr, podrías escribir un código como este:

```{r, fig.width = 6}
by_dest <- group_by(vuelos, dest)
delay <- summarize(by_dest,
  count = n(),
  dist = mean(distancia, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
)
delay <- filter(delay, count> 20, dest!= "HNL")

# Parece que las demoras aumentan con una distancia de hasta ~ 750 millas
# y luego disminuyen. Tal vez a medida que los vuelos se hacen más 
# largos, hay más habilidad para compensar las demoras en el aire?

ggplot (data = delay, mapping = aes (x = dist, y = retraso)) +
  geom_point (aes (size = count), alpha = 1/3) +
  geom_smooth (se = FALSE)
```

Hay tres pasos para preparar esta información:

1. Agrupa los vuelos por destino.

2. Resume en cada grupo para calcular la distancia, la demora promedio y el número de vuelos.

3. Filtra para eliminar puntos ruidosos y el aeropuerto de Honolulu, que está casi dos veces más lejos que el próximo aeropuerto más cercano.

Es un poco frustrante escribir este código porque tenemos que dar un nombre a cada marco de datos intermedio, aunque no nos importe. Nombrar cosas es difícil, por lo que esto de nuestro análisis más lento y complicado.

Hay otra forma de abordar el mismo problema con la tubería (del inglés pipe que también significa pipa en español), `%>%`:

```{r}
delays <- vuelos %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>% 
  filter(count > 20, dest != "HNL")
```

This focuses on the transformations, not what's being transformed, which makes the code easier to read. You can read it as a series of imperative statements: group, then summarise, then filter. As suggested by this reading, a good way to pronounce `%>%` when reading code is "then".

Behind the scenes, `x %>% f(y)` turns into `f(x, y)`, and `x %>% f(y) %>% g(z)` turns into `g(f(x, y), z)` and so on. You can use the pipe to rewrite multiple operations in a way that you can read left-to-right, top-to-bottom. We'll use piping frequently from now on because it considerably improves the readability of code, and we'll come back to it in more detail in [pipes].

Working with the pipe is one of the key criteria for belonging to the tidyverse. The only exception is ggplot2: it was written before the pipe was discovered. Unfortunately, the next iteration of ggplot2, ggvis, which does use the pipe, isn't quite ready for prime time yet. 

### Missing values

You may have wondered about the `na.rm` argument we used above. What happens if we don't set it?

```{r}
vuelos %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))
```

We get a lot of missing values! That's because aggregation functions obey the usual rule of missing values: if there's any missing value in the input, the output will be a missing value. Fortunately, all aggregation functions have an `na.rm` argument which removes the missing values prior to computation:

```{r}
vuelos %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay, na.rm = TRUE))
```

In this case, where missing values represent cancelled vuelos, we could also tackle the problem by first removing the cancelled vuelos. We'll save this dataset so we can reuse in the next few examples.

```{r}
not_cancelled <- vuelos %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))
```

### Counts

Whenever you do any aggregation, it's always a good idea to include either a count (`n()`), or a count of non-missing values (`sum(!is.na(x))`). That way you can check that you're not drawing conclusions based on very small amounts of data. For example, let's look at the planes (identified by their tail number) that have the highest average delays:

```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay)
  )

ggplot(data = delays, mapping = aes(x = delay)) + 
  geom_freqpoly(binwidth = 10)
```

Wow, there are some planes that have an _average_ delay of 5 hours (300 minutes)!

The story is actually a little more nuanced. We can get more insight if we draw a scatterplot of number of vuelos vs. average delay:

```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )

ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10)
```

Not surprisingly, there is much greater variation in the average delay when there are few vuelos. The shape of this plot is very characteristic: whenever you plot a mean (or other summary) vs. group size, you'll see that the variation decreases as the sample size increases.

When looking at this sort of plot, it's often useful to filter out the groups with the smallest numbers of observations, so you can see more of the pattern and less of the extreme variation in the smallest groups. This is what the following code does, as well as showing you a handy pattern for integrating ggplot2 into dplyr flows. It's a bit painful that you have to switch from `%>%` to `+`, but once you get the hang of it, it's quite convenient.

```{r}
delays %>% 
  filter(n > 25) %>% 
  ggplot(mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1/10)
```

--------------------------------------------------------------------------------

RStudio tip: a useful keyboard shortcut is Cmd/Ctrl + Shift + P. This resends the previously sent chunk from the editor to the console. This is very convenient when you're (e.g.) exploring the value of `n` in the example above. You send the whole block once with Cmd/Ctrl + Enter, then you modify the value of `n` and press Cmd/Ctrl + Shift + P to resend the complete block.

--------------------------------------------------------------------------------

There's another common variation of this type of pattern. Let's look at how the average performance of batters in baseball is related to the number of times they're at bat. Here I use data from the __Lahman__ package to compute the batting average (number of hits / number of attempts) of every major league baseball player.  

When I plot the skill of the batter (measured by the batting average, `ba`) against the number of opportunities to hit the ball (measured by at bat, `ab`), you see two patterns:

1.  As above, the variation in our aggregate decreases as we get more 
    data points.
    
2.  There's a positive correlation between skill (`ba`) and opportunities to 
    hit the ball (`ab`). This is because teams control who gets to play, 
    and obviously they'll pick their best players.

```{r}
# Convert to a tibble so it prints nicely
batting <- as_tibble(Lahman::Batting)

batters <- batting %>% 
  group_by(playerID) %>% 
  summarise(
    ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    ab = sum(AB, na.rm = TRUE)
  )

batters %>% 
  filter(ab > 100) %>% 
  ggplot(mapping = aes(x = ab, y = ba)) +
    geom_point() + 
    geom_smooth(se = FALSE)
```

This also has important implications for ranking. If you naively sort on `desc(ba)`, the people with the best batting averages are clearly lucky, not skilled:

```{r}
batters %>% 
  arrange(desc(ba))
```

You can find a good explanation of this problem at <http://varianceexplained.org/r/empirical_bayes_baseball/> y <http://www.evanmiller.org/how-not-to-sort-by-average-rating.html>.

### Useful summary functions {#summarise-funs}

Just using means, counts, and sum can get you a long way, but R provides many other useful summary functions:

*   Measures of location: we've used `mean(x)`, but `median(x)` is also
    useful. The mean is the sum divided by the length; the median is a value 
    where 50% of `x` is above it, and 50% is below it.
    
    It's sometimes useful to combine aggregation with logical subsetting. 
    We haven't talked about this sort of subsetting yet, but you'll learn more
    about it in [subsetting].
    
    ```{r}
    not_cancelled %>% 
      group_by(year, month, day) %>% 
      summarise(
        avg_delay1 = mean(arr_delay),
        avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay
      )
    ```

*   Measures of spread: `sd(x)`, `IQR(x)`, `mad(x)`. The root mean squared deviation,
    or standard deviation or sd for short, is the standard measure of spread.
    The interquartile range `IQR()` and median absolute deviation `mad(x)`
    are robust equivalents that may be more useful if you have outliers.
    
    ```{r}
    # Why is distance to some destinations more variable than to others?
    not_cancelled %>% 
      group_by(dest) %>% 
      summarise(distance_sd = sd(distance)) %>% 
      arrange(desc(distance_sd))
    ```
  
*   Measures of rank: `min(x)`, `quantile(x, 0.25)`, `max(x)`. Quantiles
    are a generalisation of the median. For example, `quantile(x, 0.25)`
    will find a value of `x` that is greater than 25% of the values,
    and less than the remaining 75%.

    ```{r}
    # When do the first and last vuelos leave each day?
    not_cancelled %>% 
      group_by(year, month, day) %>% 
      summarise(
        first = min(dep_time),
        last = max(dep_time)
      )
    ```
  
*   Measures of position: `first(x)`, `nth(x, 2)`, `last(x)`. These work 
    similarly to `x[1]`, `x[2]`, and `x[length(x)]` but let you set a default 
    value if that position does not exist (i.e. you're trying to get the 3rd
    element from a group that only has two elements). For example, we can
    find the first and last departure for each day:
    
    ```{r}
    not_cancelled %>% 
      group_by(year, month, day) %>% 
      summarise(
        first_dep = first(dep_time), 
        last_dep = last(dep_time)
      )
    ```
    
    These functions are complementary to filtering on ranks. Filtering gives
    you all variables, with each observation in a separate row:
    
    ```{r}
    not_cancelled %>% 
      group_by(year, month, day) %>% 
      mutate(r = min_rank(desc(dep_time))) %>% 
      filter(r %in% range(r))
    ```

*   Counts: You've seen `n()`, which takes no arguments, and returns the 
    size of the current group. To count the number of non-missing values, use
    `sum(!is.na(x))`. To count the number of distinct (unique) values, use
    `n_distinct(x)`.
    
    ```{r}
    # Which destinations have the most carriers?
    not_cancelled %>% 
      group_by(dest) %>% 
      summarise(carriers = n_distinct(carrier)) %>% 
      arrange(desc(carriers))
    ```
    
    Counts are so useful that dplyr provides a simple helper if all you want is 
    a count:
    
    ```{r}
    not_cancelled %>% 
      count(dest)
    ```
    
    You can optionally provide a weight variable. For example, you could use 
    this to "count" (sum) the total number of miles a plane flew:
    
    ```{r}
    not_cancelled %>% 
      count(tailnum, wt = distance)
    ```
  
*   Counts and proportions of logical values: `sum(x > 10)`, `mean(y == 0)`.
    When used with numeric functions, `TRUE` is converted to 1 and `FALSE` to 0. 
    This makes `sum()` and `mean()` very useful: `sum(x)` gives the number of 
    `TRUE`s in `x`, and `mean(x)` gives the proportion.
    
    ```{r}
    # How many vuelos left before 5am? (these usually indicate delayed
    # vuelos from the previous day)
    not_cancelled %>% 
      group_by(year, month, day) %>% 
      summarise(n_early = sum(dep_time < 500))
    
    # What proportion of vuelos are delayed by more than an hour?
    not_cancelled %>% 
      group_by(year, month, day) %>% 
      summarise(hour_perc = mean(arr_delay > 60))
    ```

### Grouping by multiple variables

When you group by multiple variables, each summary peels off one level of the grouping. That makes it easy to progressively roll up a dataset:

```{r}
daily <- group_by(vuelos, year, month, day)
(per_day   <- summarise(daily, vuelos = n()))
(per_month <- summarise(per_day, vuelos = sum(vuelos)))
(per_year  <- summarise(per_month, vuelos = sum(vuelos)))
```

Be careful when progressively rolling up summaries: it's OK for sums and counts, but you need to think about weighting means and variances, and it's not possible to do it exactly for rank-based statistics like the median. In other words, the sum of groupwise sums is the overall sum, but the median of groupwise medians is not the overall median.

### Ungrouping

If you need to remove grouping, and return to operations on ungrouped data, use `ungroup()`. 

```{r}
daily %>% 
  ungroup() %>%             # no longer grouped by date
  summarise(vuelos = n())  # all vuelos
```

### Ejercicios

1.  Brainstorm at least 5 different ways to assess the typical delay 
    characteristics of a group of vuelos. Consider the following scenarios:
    
    * A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of 
      the time.
      
    * A flight is always 10 minutes late.

    * A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of 
      the time.
      
    * 99% of the time a flight is on time. 1% of the time it's 2 hours late.
    
    Which is more important: arrival delay or departure delay?

1.  Come up with another approach that will give you the same output as 
    `not_cancelled %>% count(dest)` and 
    `not_cancelled %>% count(tailnum, wt = distance)` (without using 
    `count()`).

1.  Our definition of cancelled vuelos (`is.na(dep_delay) | is.na(arr_delay)`
    ) is slightly suboptimal. Why? Which is the most important column?

1.  Look at the number of cancelled vuelos per day. Is there a pattern?
    Is the proportion of cancelled vuelos related to the average delay?

1.  Which carrier has the worst delays? Challenge: can you disentangle the
    effects of bad airports vs. bad carriers? Why/why not? (Hint: think about
    `vuelos %>% group_by(carrier, dest) %>% summarise(n())`)

1.  What does the `sort` argument to `count()` do. When might you use it?

## Grouped mutates (and filters)

Grouping is most useful in conjunction with `summarise()`, but you can also do convenient operations with `mutate()` and `filter()`:

*   Find the worst members of each group:

    ```{r}
    vuelos_sml %>% 
      group_by(year, month, day) %>%
      filter(rank(desc(arr_delay)) < 10)
    ```

*   Find all groups bigger than a threshold:

    ```{r}
    popular_dests <- vuelos %>% 
      group_by(dest) %>% 
      filter(n() > 365)
    popular_dests
    ```

*   Standardise to compute per group metrics:

    ```{r}
    popular_dests %>% 
      filter(arr_delay > 0) %>% 
      mutate(prop_delay = arr_delay / sum(arr_delay)) %>% 
      select(year:day, dest, arr_delay, prop_delay)
    ```

A grouped filter is a grouped mutate followed by an ungrouped filter. I generally avoid them except for quick and dirty manipulations: otherwise it's hard to check that you've done the manipulation correctly.

Functions that work most naturally in grouped mutates and filters are known as  window functions (vs. the summary functions used for summaries). You can learn more about useful window functions in the corresponding vignette: `vignette("window-functions")`.

### Ejercicios

1. Remítete a las listas de funciones útiles de mutación y filtrado. Describe cómo cambia cada operación cuando las combinas con la agrupación.

2. ¿Qué avión (`colanum`) tiene el peor registro de tiempo?

3. ¿A qué hora del día deberías volar si quieres evitar retraso lo más posible?

4. Para cada destino, calcula los minutos totales de demora. Para cada vuelo, calcula la proporción de la demora total para su destino.

5. Los retrasos suelen estar temporalmente correlacionados: incluso una vez que el problema que causó el retraso inicial se ha resuelto, los vuelos posteriores se retrasan para permitir que salgan los vuelos anteriores. Usando `lag()`, explora cómo el retraso de un vuelo está relacionado con el retraso del vuelo inmediatamente anterior.

6. Mira cada destino. ¿Puedes encontrar vuelos sospechosamente rápidos? (es decir, vuelos que representan un posible error de entrada de datos). Calcula el tiempo en el aire de un vuelo relativo al vuelo más corto a ese destino. ¿Cuáles vuelos se retrasaron más en el aire?

7. Encuentra todos los destinos que son volados por al menos dos operadores. Usa esta información para clasificar a los transportistas.

8. Para cada avión, cuenta el número de vuelos antes del primer retraso de más de 1 hora.
